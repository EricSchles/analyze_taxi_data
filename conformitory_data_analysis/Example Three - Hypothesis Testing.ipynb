{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conformitory Data Analysis - Hypothesis Testing\n",
    "\n",
    "Below we will see how to formulate and test hypotheses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis Testing with Scipy\n",
    "\n",
    "Now that we have an understanding of how data looks and behaves, we'll extend our analysis to looking at how data can be analyzed when we assume a pattern and then verify it, rather than letting the data tell us whatever it wants.  This is conceptually different than exploratory analysis and is referred to as conformity analysis, because we are assessing whether the data conforms to our intuition of the world.\n",
    "\n",
    "A great library for doing this kind of analysis is Scipy.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "green = pd.read_csv(\"green_tripdata_2015-09.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.841834939249647, 0.0)\n",
      "SpearmanrResult(correlation=0.9290809466065404, pvalue=0.0)\n",
      "MannwhitneyuResult(statistic=2077508407340.0, pvalue=0.0)\n",
      "WilcoxonResult(statistic=2005824165.5, pvalue=0.0)\n",
      "Ks_2sampResult(statistic=0.7510217897073166, pvalue=0.0)\n"
     ]
    }
   ],
   "source": [
    "print(stats.pearsonr(green[\"Fare_amount\"], green[\"Trip_distance\"]))\n",
    "print(stats.spearmanr(green[\"Fare_amount\"], green[\"Trip_distance\"]))\n",
    "print(stats.mannwhitneyu(green[\"Fare_amount\"], green[\"Trip_distance\"], alternative=\"two-sided\"))\n",
    "print(stats.wilcoxon(green[\"Fare_amount\"], green[\"Trip_distance\"]))\n",
    "print(stats.ks_2samp(green[\"Fare_amount\"], green[\"Trip_distance\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we include various statistical tests that ask related questions. Each of these statistical tests, at a high level asks, is there a relationship between these two variables?\n",
    "\n",
    "The first two - pearson and spearman ask, is there a correlation between the two variables? So as one varies, does the other? The null hypothesis for both tests is, that there is no correlation, and the altnerative is that there is a correlation. By looking at the pvalues of both tests, we see that there is in fact a correlation. The first parameter tells us the strength of the correlation.\n",
    "\n",
    "In a sense we can think of the first test as a parametric test, because it relies on a distribution. In this case it relies on the bivariate normal distribution and assumes there is a linear correlation between the variables.\n",
    "\n",
    "Given this context, we can conclude a strong positive linear correlation.\n",
    "\n",
    "The spearman test, gives us a slightly more nuanced view into this correlation. It is distribution-free, since its a nonparametric test. It is distribution free, in the sense that it measures the rank correlation between the variables. A rank correlation that looks at the data points based on their ordering, rather than their distribution.\n",
    "\n",
    "Given this notion of a rank ordering of variables, we relax the normality assumption and allow for monotonic correlations. So, for the above a correlation of 0.92 and a pvalue of 0 means that the data is correlated with a mostly linear relationship (from pearson) but some of the data having a strong monotonic correlation.\n",
    "\n",
    "Next we turn our attention to the remaining statistical tests - Mann Whitney-U and Wilcoxon.\n",
    "\n",
    "The two-sided Mann Whitney-U test asks the question:\n",
    "\n",
    "Given the two sample distributions, what is the probability that a randomly selected value from the first distribution will be equal to a random sample from the second distribution. With a pvalue of zero we must reject the null hypothesis. So while these variables have a strong positive correlation, they don't come from the same distribution.\n",
    "\n",
    "The wilcoxon test asks a similar question -\n",
    "\n",
    "What is the probability that the difference between pairs follows a symmetric distribution around zero? With a pvalue of zero we reject the null hypothesis that it does. And so we must conclude that the differences are not symmetric around a mean of zero. This gives us further evidence that the two variables do not come from the same distribution.\n",
    "\n",
    "Finally, we will look at the KS-2sample test -\n",
    "\n",
    "What is the probability the two samples come from the same underlying continuous distribution? With a pvalue of zero we reject the null hypothesis that it does. So these absolutely are not the same random variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
